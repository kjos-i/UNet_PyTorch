from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms
import os
from PIL import Image


class MyDataset(Dataset):
    def __init__(self, root_path, transform, limit=None):
        super().__init__()
        
        self.root_path = root_path
        self.limit = limit
        self.images = sorted([root_path + "/train/" + i for i in os.listdir(root_path + "/train/")])[:self.limit]
        self.masks = sorted([root_path + "/train_masks/" + i for i in os.listdir(root_path + "/train_masks/")])[:self.limit]

        if transform == "transform_augmentation":
            self.transform = transforms.Compose([
                transforms.RandomVerticalFlip(p=0.25),
                transforms.RandomHorizontalFlip(p=0.25),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
                transforms.Resize((512, 512)),
                transforms.ToTensor()
                ])

        if transform == "transform":
            self.transform = transforms.Compose([
                transforms.Resize((512, 512)),
                transforms.ToTensor()
                ])
        
        if self.limit is None:
            self.limit = len(self.images)


    def __getitem__(self, index):
        img = Image.open(self.images[index]).convert("RGB")
        mask = Image.open(self.masks[index]).convert("L")

        return self.transform(img), self.transform(mask)
        

    def __len__(self):
        return min(len(self.images), self.limit)
